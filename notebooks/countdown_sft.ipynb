{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import importlib\n",
    "\n",
    "from peft import LoraConfig\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.train\n",
    "import src.model\n",
    "import data.countdown\n",
    "\n",
    "importlib.reload(src.train)\n",
    "importlib.reload(src.model)\n",
    "importlib.reload(data.countdown)\n",
    "\n",
    "from src.train import sft_train_lora\n",
    "from src.model import identify_target_modules\n",
    "from data.countdown import Countdown\n",
    "from data.format import chat_format_qa_instance, lm_format_qa_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Countdown(json_file=os.environ[\"COUNTDOWN_DATASET\"])\n",
    "\n",
    "use_chat_format = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_example = dataset[0]\n",
    "few_shot_prompt = (\n",
    "    f\"Here is an example:\\n\"\n",
    "    f\"{few_shot_example['question']}\"\n",
    "    f\"{few_shot_example['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'The target is: 100\\nThe available numbers are: [70, 63, 75, 32]\\nDescribe how to reach the target using the given numbers.',\n",
       " 'answer': \"The search path used for this problem was: Current State: 100:[70, 63, 75, 32], Operations: []\\nExploring Operation: 75-70=5, Resulting Numbers: [63, 32, 5]\\nGenerated Node #0,0: 100:[63, 32, 5] Operation: 75-70=5\\nMoving to Node #0,0\\nCurrent State: 100:[63, 32, 5], Operations: ['75-70=5']\\nExploring Operation: 63+32=95, Resulting Numbers: [5, 95]\\nGenerated Node #0,0,0: 100:[5, 95] Operation: 63+32=95\\nMoving to Node #0,0,0\\nCurrent State: 100:[5, 95], Operations: ['75-70=5', '63+32=95']\\nExploring Operation: 5+95=100, Resulting Numbers: [100]\\n100,100 equal: Goal Reached\\n\\nThe optimal path was: Current State: 100:[70, 63, 75, 32], Operations: []\\nExploring Operation: 70-63=7, Resulting Numbers: [75, 32, 7]\\nGenerated Node #2: [75, 32, 7] from Operation: 70-63=7\\nCurrent State: 100:[75, 32, 7], Operations: ['70-63=7']\\nExploring Operation: 75+32=107, Resulting Numbers: [7, 107]\\nGenerated Node #3: [7, 107] from Operation: 75+32=107\\nCurrent State: 100:[7, 107], Operations: ['70-63=7', '75+32=107']\\nExploring Operation: 107-7=100, Resulting Numbers: [100]\\n100,100 equal: Goal Reached\\n\\nThe final solution was: ['70-63=7', '75+32=107', '107-7=100']\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is an example:\\nThe target is: 100\\nThe available numbers are: [70, 63, 75, 32]\\nDescribe how to reach the target using the given numbers.The search path used for this problem was: Current State: 100:[70, 63, 75, 32], Operations: []\\nExploring Operation: 75-70=5, Resulting Numbers: [63, 32, 5]\\nGenerated Node #0,0: 100:[63, 32, 5] Operation: 75-70=5\\nMoving to Node #0,0\\nCurrent State: 100:[63, 32, 5], Operations: ['75-70=5']\\nExploring Operation: 63+32=95, Resulting Numbers: [5, 95]\\nGenerated Node #0,0,0: 100:[5, 95] Operation: 63+32=95\\nMoving to Node #0,0,0\\nCurrent State: 100:[5, 95], Operations: ['75-70=5', '63+32=95']\\nExploring Operation: 5+95=100, Resulting Numbers: [100]\\n100,100 equal: Goal Reached\\n\\nThe optimal path was: Current State: 100:[70, 63, 75, 32], Operations: []\\nExploring Operation: 70-63=7, Resulting Numbers: [75, 32, 7]\\nGenerated Node #2: [75, 32, 7] from Operation: 70-63=7\\nCurrent State: 100:[75, 32, 7], Operations: ['70-63=7']\\nExploring Operation: 75+32=107, Resulting Numbers: [7, 107]\\nGenerated Node #3: [7, 107] from Operation: 75+32=107\\nCurrent State: 100:[7, 107], Operations: ['70-63=7', '75+32=107']\\nExploring Operation: 107-7=100, Resulting Numbers: [100]\\n100,100 equal: Goal Reached\\n\\nThe final solution was: ['70-63=7', '75+32=107', '107-7=100']\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_with_few_shot(example, use_chat_format=True):\n",
    "    task_description = (\n",
    "        \"You are tasked to solve arithmetic reasoning problems. \"\n",
    "        \"Given a set of numbers and a target, describe the steps in the path to reach the target using those numbers.\"\n",
    "    )\n",
    "    guidelines = (\n",
    "        \"Using arithmetic operations such as addition (+), subtraction (-), multiplication (*) and division (/), \"\n",
    "        \"use the initial set of numbers to gather new numbers that eventually reach the target in the end.\"\n",
    "    )\n",
    "\n",
    "    # Format the dataset using the appropriate format\n",
    "    if use_chat_format:\n",
    "        return [\n",
    "                {\"role\": \"user\", \"content\": f\"{task_description}\\n{guidelines}\\n{few_shot_prompt}\\n{example[\"question\"]}\"},\n",
    "                {\"role\": \"assistant\", \"content\": example[\"answer\"]}\n",
    "            ]\n",
    "        \n",
    "    else:\n",
    "        return (\n",
    "            f\"### Question {task_description}\\n{guidelines}\\n{few_shot_prompt}\\n{example[\"question\"]}\\n\"\n",
    "            f\"### Answer {example[\"answer\"]}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data = [format_with_few_shot(example, use_chat_format) for example in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_chat_format:\n",
    "    MODEL_NAME = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "else:\n",
    "    MODEL_NAME = \"facebook/opt-125m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meta-llama/Llama-3.2-1B-Instruct'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146913826c7e496d802c4d8786ab5563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/172552 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, token=os.environ[\"HF_TOKEN\"])\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=os.environ[\"HF_TOKEN\"])\n",
    "\n",
    "# Create a Dataset object with formatted text\n",
    "dataset = Dataset.from_dict({\"chat\": formatted_data})\n",
    "dataset = dataset.map(\n",
    "    lambda x: {\"formatted_text\": tokenizer.apply_chat_template(x[\"chat\"], tokenize=False, add_generation_prompt=False)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat': [{'content': \"You are tasked to solve arithmetic reasoning problems. Given a set of numbers and a target, describe the steps in the path to reach the target using those numbers.\\nUsing arithmetic operations such as addition (+), subtraction (-), multiplication (*) and division (/), use the initial set of numbers to gather new numbers that eventually reach the target in the end.\\nHere is an example:\\nThe target is: 100\\nThe available numbers are: [70, 63, 75, 32]\\nDescribe how to reach the target using the given numbers.The search path used for this problem was: Current State: 100:[70, 63, 75, 32], Operations: []\\nExploring Operation: 75-70=5, Resulting Numbers: [63, 32, 5]\\nGenerated Node #0,0: 100:[63, 32, 5] Operation: 75-70=5\\nMoving to Node #0,0\\nCurrent State: 100:[63, 32, 5], Operations: ['75-70=5']\\nExploring Operation: 63+32=95, Resulting Numbers: [5, 95]\\nGenerated Node #0,0,0: 100:[5, 95] Operation: 63+32=95\\nMoving to Node #0,0,0\\nCurrent State: 100:[5, 95], Operations: ['75-70=5', '63+32=95']\\nExploring Operation: 5+95=100, Resulting Numbers: [100]\\n100,100 equal: Goal Reached\\n\\nThe optimal path was: Current State: 100:[70, 63, 75, 32], Operations: []\\nExploring Operation: 70-63=7, Resulting Numbers: [75, 32, 7]\\nGenerated Node #2: [75, 32, 7] from Operation: 70-63=7\\nCurrent State: 100:[75, 32, 7], Operations: ['70-63=7']\\nExploring Operation: 75+32=107, Resulting Numbers: [7, 107]\\nGenerated Node #3: [7, 107] from Operation: 75+32=107\\nCurrent State: 100:[7, 107], Operations: ['70-63=7', '75+32=107']\\nExploring Operation: 107-7=100, Resulting Numbers: [100]\\n100,100 equal: Goal Reached\\n\\nThe final solution was: ['70-63=7', '75+32=107', '107-7=100']\\nThe target is: 100\\nThe available numbers are: [70, 63, 75, 32]\\nDescribe how to reach the target using the given numbers.\",\n",
       "   'role': 'user'},\n",
       "  {'content': \"The search path used for this problem was: Current State: 100:[70, 63, 75, 32], Operations: []\\nExploring Operation: 75-70=5, Resulting Numbers: [63, 32, 5]\\nGenerated Node #0,0: 100:[63, 32, 5] Operation: 75-70=5\\nMoving to Node #0,0\\nCurrent State: 100:[63, 32, 5], Operations: ['75-70=5']\\nExploring Operation: 63+32=95, Resulting Numbers: [5, 95]\\nGenerated Node #0,0,0: 100:[5, 95] Operation: 63+32=95\\nMoving to Node #0,0,0\\nCurrent State: 100:[5, 95], Operations: ['75-70=5', '63+32=95']\\nExploring Operation: 5+95=100, Resulting Numbers: [100]\\n100,100 equal: Goal Reached\\n\\nThe optimal path was: Current State: 100:[70, 63, 75, 32], Operations: []\\nExploring Operation: 70-63=7, Resulting Numbers: [75, 32, 7]\\nGenerated Node #2: [75, 32, 7] from Operation: 70-63=7\\nCurrent State: 100:[75, 32, 7], Operations: ['70-63=7']\\nExploring Operation: 75+32=107, Resulting Numbers: [7, 107]\\nGenerated Node #3: [7, 107] from Operation: 75+32=107\\nCurrent State: 100:[7, 107], Operations: ['70-63=7', '75+32=107']\\nExploring Operation: 107-7=100, Resulting Numbers: [100]\\n100,100 equal: Goal Reached\\n\\nThe final solution was: ['70-63=7', '75+32=107', '107-7=100']\",\n",
       "   'role': 'assistant'}],\n",
       " 'formatted_text': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 01 Dec 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are tasked to solve arithmetic reasoning problems. Given a set of numbers and a target, describe the steps in the path to reach the target using those numbers.\\nUsing arithmetic operations such as addition (+), subtraction (-), multiplication (*) and division (/), use the initial set of numbers to gather new numbers that eventually reach the target in the end.\\nHere is an example:\\nThe target is: 100\\nThe available numbers are: [70, 63, 75, 32]\\nDescribe how to reach the target using the given numbers.The search path used for this problem was: Current State: 100:[70, 63, 75, 32], Operations: []\\nExploring Operation: 75-70=5, Resulting Numbers: [63, 32, 5]\\nGenerated Node #0,0: 100:[63, 32, 5] Operation: 75-70=5\\nMoving to Node #0,0\\nCurrent State: 100:[63, 32, 5], Operations: ['75-70=5']\\nExploring Operation: 63+32=95, Resulting Numbers: [5, 95]\\nGenerated Node #0,0,0: 100:[5, 95] Operation: 63+32=95\\nMoving to Node #0,0,0\\nCurrent State: 100:[5, 95], Operations: ['75-70=5', '63+32=95']\\nExploring Operation: 5+95=100, Resulting Numbers: [100]\\n100,100 equal: Goal Reached\\n\\nThe optimal path was: Current State: 100:[70, 63, 75, 32], Operations: []\\nExploring Operation: 70-63=7, Resulting Numbers: [75, 32, 7]\\nGenerated Node #2: [75, 32, 7] from Operation: 70-63=7\\nCurrent State: 100:[75, 32, 7], Operations: ['70-63=7']\\nExploring Operation: 75+32=107, Resulting Numbers: [7, 107]\\nGenerated Node #3: [7, 107] from Operation: 75+32=107\\nCurrent State: 100:[7, 107], Operations: ['70-63=7', '75+32=107']\\nExploring Operation: 107-7=100, Resulting Numbers: [100]\\n100,100 equal: Goal Reached\\n\\nThe final solution was: ['70-63=7', '75+32=107', '107-7=100']\\nThe target is: 100\\nThe available numbers are: [70, 63, 75, 32]\\nDescribe how to reach the target using the given numbers.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe search path used for this problem was: Current State: 100:[70, 63, 75, 32], Operations: []\\nExploring Operation: 75-70=5, Resulting Numbers: [63, 32, 5]\\nGenerated Node #0,0: 100:[63, 32, 5] Operation: 75-70=5\\nMoving to Node #0,0\\nCurrent State: 100:[63, 32, 5], Operations: ['75-70=5']\\nExploring Operation: 63+32=95, Resulting Numbers: [5, 95]\\nGenerated Node #0,0,0: 100:[5, 95] Operation: 63+32=95\\nMoving to Node #0,0,0\\nCurrent State: 100:[5, 95], Operations: ['75-70=5', '63+32=95']\\nExploring Operation: 5+95=100, Resulting Numbers: [100]\\n100,100 equal: Goal Reached\\n\\nThe optimal path was: Current State: 100:[70, 63, 75, 32], Operations: []\\nExploring Operation: 70-63=7, Resulting Numbers: [75, 32, 7]\\nGenerated Node #2: [75, 32, 7] from Operation: 70-63=7\\nCurrent State: 100:[75, 32, 7], Operations: ['70-63=7']\\nExploring Operation: 75+32=107, Resulting Numbers: [7, 107]\\nGenerated Node #3: [7, 107] from Operation: 75+32=107\\nCurrent State: 100:[7, 107], Operations: ['70-63=7', '75+32=107']\\nExploring Operation: 107-7=100, Resulting Numbers: [100]\\n100,100 equal: Goal Reached\\n\\nThe final solution was: ['70-63=7', '75+32=107', '107-7=100']<|eot_id|>\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172552"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj']\n"
     ]
    }
   ],
   "source": [
    "target_modules = identify_target_modules(model, name_segment='self_attn')\n",
    "print(target_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    target_modules=target_modules,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287faf693c1d4bdabf7aeb88dffbffa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/172552 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8849396c3f2549a3ae8fe2ce4be8e2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/172552 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "WandbCallback requires wandb to be installed. Run `pip install wandb`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msft_train_lora\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msft_lora\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m### Answer:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/llm-reasoning-decomp/src/train.py:95\u001b[0m, in \u001b[0;36msft_train_lora\u001b[0;34m(base_model, train_dataset, eval_dataset, tokenizer, adapter_name, formatting_prompts_func, response_template, lora_config, training_args, save_dir, content_key)\u001b[0m\n\u001b[1;32m     92\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWANDB_LOG_MODEL\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWANDB_WATCH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 95\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mSFTTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpeft_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformatting_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatting_prompts_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_dir:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:401\u001b[0m, in \u001b[0;36mSFTTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics, peft_config, dataset_text_field, packing, formatting_func, max_seq_length, infinite, num_of_sequences, chars_per_token, dataset_num_proc, dataset_batch_size, neftune_noise_alpha, model_init_kwargs, dataset_kwargs, eval_packing)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    396\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` to your code.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m     )\n\u001b[0;32m--> 401\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;66;03m# Add tags for models that have been loaded with the correct transformers version\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd_model_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages/transformers/trainer.py:598\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    596\u001b[0m default_callbacks \u001b[38;5;241m=\u001b[39m DEFAULT_CALLBACKS \u001b[38;5;241m+\u001b[39m get_reporting_integration_callbacks(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mreport_to)\n\u001b[1;32m    597\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m default_callbacks \u001b[38;5;28;01mif\u001b[39;00m callbacks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m default_callbacks \u001b[38;5;241m+\u001b[39m callbacks\n\u001b[0;32m--> 598\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler \u001b[38;5;241m=\u001b[39m \u001b[43mCallbackHandler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_callback(PrinterCallback \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdisable_tqdm \u001b[38;5;28;01melse\u001b[39;00m DEFAULT_PROGRESS_CALLBACK)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# Will be set to True by `self._setup_loggers()` on first call to `self.log()`.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages/transformers/trainer_callback.py:409\u001b[0m, in \u001b[0;36mCallbackHandler.__init__\u001b[0;34m(self, callbacks, model, tokenizer, optimizer, lr_scheduler)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m tokenizer\n",
      "File \u001b[0;32m/opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages/transformers/trainer_callback.py:426\u001b[0m, in \u001b[0;36mCallbackHandler.add_callback\u001b[0;34m(self, callback)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_callback\u001b[39m(\u001b[38;5;28mself\u001b[39m, callback):\n\u001b[0;32m--> 426\u001b[0m     cb \u001b[38;5;241m=\u001b[39m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callback, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m callback\n\u001b[1;32m    427\u001b[0m     cb_class \u001b[38;5;241m=\u001b[39m callback \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callback, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m callback\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cb_class \u001b[38;5;129;01min\u001b[39;00m [c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages/transformers/integrations/integration_utils.py:767\u001b[0m, in \u001b[0;36mWandbCallback.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    765\u001b[0m has_wandb \u001b[38;5;241m=\u001b[39m is_wandb_available()\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_wandb:\n\u001b[0;32m--> 767\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWandbCallback requires wandb to be installed. Run `pip install wandb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_wandb:\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: WandbCallback requires wandb to be installed. Run `pip install wandb`."
     ]
    }
   ],
   "source": [
    "sft_train_lora(\n",
    "    base_model=model,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    adapter_name=\"sft_lora\",\n",
    "    response_template=\"### Answer:\",\n",
    "    lora_config=lora_config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoning-decomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
