{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import pytorch_utils as torch_utils\n",
    "from peft import LoraConfig\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.train\n",
    "import src.model\n",
    "\n",
    "importlib.reload(src.train)\n",
    "importlib.reload(src.model)\n",
    "\n",
    "from src.train import sft_train_lora\n",
    "from src.model import identify_target_modules\n",
    "from data.gsm8k import GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from ipywidgets) (8.28.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7241ed3fb0404fb1b793c21176490e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"lucasmccabe-lmi/CodeAlpaca-20k\", split=\"train\")\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "\n",
    "dataset = GSM8K(tokenizer=tokenizer)\n",
    "\n",
    "dataset = Dataset.from_dict({\"input_text\" : [example[\"input_text\"] for example in dataset]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_text'],\n",
       "    num_rows: 7473\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_text': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? ### Answer: Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7473"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.decoder.layers.0.self_attn.k_proj',\n",
       " 'model.decoder.layers.0.self_attn.v_proj',\n",
       " 'model.decoder.layers.0.self_attn.q_proj',\n",
       " 'model.decoder.layers.0.self_attn.out_proj',\n",
       " 'model.decoder.layers.1.self_attn.k_proj',\n",
       " 'model.decoder.layers.1.self_attn.v_proj',\n",
       " 'model.decoder.layers.1.self_attn.q_proj',\n",
       " 'model.decoder.layers.1.self_attn.out_proj',\n",
       " 'model.decoder.layers.2.self_attn.k_proj',\n",
       " 'model.decoder.layers.2.self_attn.v_proj',\n",
       " 'model.decoder.layers.2.self_attn.q_proj',\n",
       " 'model.decoder.layers.2.self_attn.out_proj',\n",
       " 'model.decoder.layers.3.self_attn.k_proj',\n",
       " 'model.decoder.layers.3.self_attn.v_proj',\n",
       " 'model.decoder.layers.3.self_attn.q_proj',\n",
       " 'model.decoder.layers.3.self_attn.out_proj',\n",
       " 'model.decoder.layers.4.self_attn.k_proj',\n",
       " 'model.decoder.layers.4.self_attn.v_proj',\n",
       " 'model.decoder.layers.4.self_attn.q_proj',\n",
       " 'model.decoder.layers.4.self_attn.out_proj',\n",
       " 'model.decoder.layers.5.self_attn.k_proj',\n",
       " 'model.decoder.layers.5.self_attn.v_proj',\n",
       " 'model.decoder.layers.5.self_attn.q_proj',\n",
       " 'model.decoder.layers.5.self_attn.out_proj',\n",
       " 'model.decoder.layers.6.self_attn.k_proj',\n",
       " 'model.decoder.layers.6.self_attn.v_proj',\n",
       " 'model.decoder.layers.6.self_attn.q_proj',\n",
       " 'model.decoder.layers.6.self_attn.out_proj',\n",
       " 'model.decoder.layers.7.self_attn.k_proj',\n",
       " 'model.decoder.layers.7.self_attn.v_proj',\n",
       " 'model.decoder.layers.7.self_attn.q_proj',\n",
       " 'model.decoder.layers.7.self_attn.out_proj',\n",
       " 'model.decoder.layers.8.self_attn.k_proj',\n",
       " 'model.decoder.layers.8.self_attn.v_proj',\n",
       " 'model.decoder.layers.8.self_attn.q_proj',\n",
       " 'model.decoder.layers.8.self_attn.out_proj',\n",
       " 'model.decoder.layers.9.self_attn.k_proj',\n",
       " 'model.decoder.layers.9.self_attn.v_proj',\n",
       " 'model.decoder.layers.9.self_attn.q_proj',\n",
       " 'model.decoder.layers.9.self_attn.out_proj',\n",
       " 'model.decoder.layers.10.self_attn.k_proj',\n",
       " 'model.decoder.layers.10.self_attn.v_proj',\n",
       " 'model.decoder.layers.10.self_attn.q_proj',\n",
       " 'model.decoder.layers.10.self_attn.out_proj',\n",
       " 'model.decoder.layers.11.self_attn.k_proj',\n",
       " 'model.decoder.layers.11.self_attn.v_proj',\n",
       " 'model.decoder.layers.11.self_attn.q_proj',\n",
       " 'model.decoder.layers.11.self_attn.out_proj',\n",
       " 'model.decoder.layers.12.self_attn.k_proj',\n",
       " 'model.decoder.layers.12.self_attn.v_proj',\n",
       " 'model.decoder.layers.12.self_attn.q_proj',\n",
       " 'model.decoder.layers.12.self_attn.out_proj',\n",
       " 'model.decoder.layers.13.self_attn.k_proj',\n",
       " 'model.decoder.layers.13.self_attn.v_proj',\n",
       " 'model.decoder.layers.13.self_attn.q_proj',\n",
       " 'model.decoder.layers.13.self_attn.out_proj',\n",
       " 'model.decoder.layers.14.self_attn.k_proj',\n",
       " 'model.decoder.layers.14.self_attn.v_proj',\n",
       " 'model.decoder.layers.14.self_attn.q_proj',\n",
       " 'model.decoder.layers.14.self_attn.out_proj',\n",
       " 'model.decoder.layers.15.self_attn.k_proj',\n",
       " 'model.decoder.layers.15.self_attn.v_proj',\n",
       " 'model.decoder.layers.15.self_attn.q_proj',\n",
       " 'model.decoder.layers.15.self_attn.out_proj',\n",
       " 'model.decoder.layers.16.self_attn.k_proj',\n",
       " 'model.decoder.layers.16.self_attn.v_proj',\n",
       " 'model.decoder.layers.16.self_attn.q_proj',\n",
       " 'model.decoder.layers.16.self_attn.out_proj',\n",
       " 'model.decoder.layers.17.self_attn.k_proj',\n",
       " 'model.decoder.layers.17.self_attn.v_proj',\n",
       " 'model.decoder.layers.17.self_attn.q_proj',\n",
       " 'model.decoder.layers.17.self_attn.out_proj',\n",
       " 'model.decoder.layers.18.self_attn.k_proj',\n",
       " 'model.decoder.layers.18.self_attn.v_proj',\n",
       " 'model.decoder.layers.18.self_attn.q_proj',\n",
       " 'model.decoder.layers.18.self_attn.out_proj',\n",
       " 'model.decoder.layers.19.self_attn.k_proj',\n",
       " 'model.decoder.layers.19.self_attn.v_proj',\n",
       " 'model.decoder.layers.19.self_attn.q_proj',\n",
       " 'model.decoder.layers.19.self_attn.out_proj',\n",
       " 'model.decoder.layers.20.self_attn.k_proj',\n",
       " 'model.decoder.layers.20.self_attn.v_proj',\n",
       " 'model.decoder.layers.20.self_attn.q_proj',\n",
       " 'model.decoder.layers.20.self_attn.out_proj',\n",
       " 'model.decoder.layers.21.self_attn.k_proj',\n",
       " 'model.decoder.layers.21.self_attn.v_proj',\n",
       " 'model.decoder.layers.21.self_attn.q_proj',\n",
       " 'model.decoder.layers.21.self_attn.out_proj',\n",
       " 'model.decoder.layers.22.self_attn.k_proj',\n",
       " 'model.decoder.layers.22.self_attn.v_proj',\n",
       " 'model.decoder.layers.22.self_attn.q_proj',\n",
       " 'model.decoder.layers.22.self_attn.out_proj',\n",
       " 'model.decoder.layers.23.self_attn.k_proj',\n",
       " 'model.decoder.layers.23.self_attn.v_proj',\n",
       " 'model.decoder.layers.23.self_attn.q_proj',\n",
       " 'model.decoder.layers.23.self_attn.out_proj']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_modules = identify_target_modules(model, name_segment='self_attn')\n",
    "target_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    target_modules=target_modules,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a260c0da94054202bc8252589a39cb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84c51366697466398a97b34b4390a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/reasoning-decomp/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbaedf9cf18412583e65ad30b424a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2805 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sft_train_lora(\n",
    "    base_model=model,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"facebook/opt-350m\"),\n",
    "    adapter_name=\"sft_lora\",\n",
    "    response_template=\" ### Answer:\",\n",
    "    lora_config=lora_config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoning-decomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
